{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71cb104c-588c-4a0d-b888-6c8449a2bc01",
   "metadata": {},
   "source": [
    "# Tokenizing and Translating Markdown with OpenAI\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this notebook, we will implement a pipeline to tokenize a markdown document, split it into chunks at multiple newlines, translate those chunks using OpenAI's LLMs, and reconstruct the full document while retaining original formatting.\n",
    "\n",
    "Specifically, we will:\n",
    "\n",
    "- Read in a markdown file \n",
    "- Tokenize the text into words, punctuation, etc.\n",
    "- Count the number of tokens\n",
    "- Split the tokens into chunks whenever there are multiple successive newlines \n",
    "- Translate each chunk into another language using OpenAI's translation LLMs\n",
    "- Reconstruct the translated chunks into a full document, preserving original formatting like headers, lists, etc.\n",
    "\n",
    "This allows us to get translations while keeping code blocks, images, tables intact. \n",
    "\n",
    "We'll use Python and Jupyter notebooks to implement the pipeline. The notebook will be structured into sections for each step of the process.\n",
    "\n",
    "To follow along, you'll want a markdown file to process. We'll use a small sample file included with the notebook. You'll need access to OpenAI's API.\n",
    "\n",
    "Let's get started! First we'll import the modules and setup the notebook. Then we'll define functions for each step - tokenizing, counting tokens, splitting, translating, and reconstructing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5231a58-0458-473d-a802-4f5f0caafe94",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3db365a-1cf2-4936-ae1f-131f1894a7fe",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46ff99b0-5fb7-407f-9a2a-be72da68098f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_language = \"english\"\n",
    "output_language = \"french\" \n",
    "format = \"markdown\" # any special formatting considerations (e.g. .arb file, markdown, json, plain text, or multiple)\n",
    "splitter = \"\\n\\n\" # the split string used to segment the chunks within the text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c2c0fa-a4be-4ab7-89cc-0e9a692e0660",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f201397c-c5e3-4229-934a-57b640b7d511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.5.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tiktoken) (2023.6.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken) (2023.5.7)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44dbb258-e065-4a27-9296-d9e346b49cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai, tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504e7129-7ae8-4b4c-8a67-c108aa531cf2",
   "metadata": {},
   "source": [
    "### Import Input File"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec6c37e-812d-4191-82a1-3080d5b0fb6a",
   "metadata": {},
   "source": [
    "Import the data file you want translated from `data/input.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1cf352f-2246-4aee-bd86-1c034cab0afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/input.txt\", \"r\") as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d121723-ed09-48b0-a7c5-2441eae8526c",
   "metadata": {},
   "source": [
    "Length of the text file (for our purposes, we'll be using a small sample text):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ac60e6b-43bb-4fc2-99ac-3f1f975a6c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5667"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546ddad7-463e-4e3c-ac61-7b6305c7683b",
   "metadata": {},
   "source": [
    "### Counting the tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a66a822-dddb-4eda-8ce5-f148461d3d8e",
   "metadata": {},
   "source": [
    "We'll use OpenAI's `tiktoken` - a fast open-source tokenizer:\n",
    "\n",
    "> Given a text string (e.g., `\"tiktoken is great!\"`) and an encoding (e.g., `\"cl100k_base\"`), a tokenizer can split the text string into a list of tokens (e.g., `[\"t\", \"ik\", \"token\", \" is\", \" great\", \"!\"]`).\n",
    "\n",
    "> Splitting text strings into tokens is useful because GPT models see text in the form of tokens. Knowing how many tokens are in a text string can tell you (a) whether the string is too long for a text model to process and (b) how much an OpenAI API call costs (as usage is priced by token)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "effb6066-1756-4e1f-af01-497db122aebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "encoded_text = encoding.encode(text)\n",
    "input_token_count = len(encoded_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b67afe42-81e7-4b3d-b8e9-ea60f37aaecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1062"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_token_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a87c864-2da1-4881-abd6-8239c337a246",
   "metadata": {},
   "source": [
    "### Split the file into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2b1e6b9-2ab9-4c06-bc52-ed12434929df",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_text = text.split(splitter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4177b0-1f86-4f90-bb11-0659330d1a9c",
   "metadata": {},
   "source": [
    "The number of chunks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55936406-a1d0-40bd-adeb-90c11ecf8412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(split_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7202ddfa-03e5-45c1-b02c-b5c5e9e389b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "longest_chunk = max(split_text, key=len)\n",
    "max_len = len(longest_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a13bfca-3041-40a1-ae75-32f81b420251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'*   **Rank Tracking** - Monitoring keyword rankings manually is time consuming. Automated rank trackers refresh data continuously.\\n*   **Site Audits** - Crawling sites for issues like broken links and metadata problems is a rote task. Automated site audit tools can find 135+ problems.\\n*   **Brand Monitoring** - Tracking brand mentions and monitoring backlinks is tedious without automation. Brand monitoring tools automatically aggregate this data.\\n*   **Reporting** - Manual reporting in Excel or Data Studio is inefficient. Automated SEO reporting dashboards provide one-click access to data.\\n*   **Image Optimization** - With the rise of visual SERPs, image optimization is critical but laborious. Automated image compressors and upscalers streamline this.\\n*   **Site Speed Enhancements** - Page speed improvements like compressing images can be automated to run site-wide.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longest_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5a18fc7-434a-4a63-96f9-3b3eac2f6baa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "878"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e4656c6-47d4-448d-b93f-ca6b21961ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"You are a translation platform. You receive a string in a {format} format and written in {input_language}, and solely return the same string in {output_language} while retaining the {format} formatting. Your translations are accurate, aiming not to deviate from the original structure, content, writing style and tone.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d37f5272-21c8-4042-b678-a0400b435286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are a translation platform. You receive a string in a markdown format and written in english, and solely return the same string in french while retaining the markdown formatting. Your translations are accurate, aiming not to deviate from the original structure, content, writing style and tone.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915a55ec-2439-4f13-a52d-fea6918d3a83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
